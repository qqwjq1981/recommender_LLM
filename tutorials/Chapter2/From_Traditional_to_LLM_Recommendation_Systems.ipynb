{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial: From Traditional to LLM-Based Recommendations Using MovieLens Dataset\n",
        "\n",
        "#### Objective\n",
        "- Transitioning from traditional recommendation methods to LLM-based approaches.\n",
        "- Challenges: Scalability, cold start problem, lack of context-awareness.\n",
        "- LLM Importance: Contextual understanding, multimodal data handling, and enhanced personalization."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting Up the Environment\n",
        "\n",
        "**Install Required Libraries**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas scikit-learn matplotlib surprise transformers torch"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.23.5)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.3.5)\nRequirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.1.3)\nRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (3.9.2)\nRequirement already satisfied: surprise in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (0.1)\nRequirement already satisfied: transformers in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (4.36.2)\nRequirement already satisfied: torch in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.13.1)\nRequirement already satisfied: pytz>=2017.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pandas) (2022.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: joblib>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: scipy>=1.3.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from scikit-learn) (3.4.0)\nRequirement already satisfied: importlib-resources>=3.2.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (6.1.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: pillow>=8 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (9.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from matplotlib) (24.0)\nRequirement already satisfied: scikit-surprise in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from surprise) (1.1.4)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (3.14.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tqdm>=4.27 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (4.66.2)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (2024.4.28)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from torch) (4.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\nRequirement already satisfied: zipp>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.12.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests->transformers) (3.7)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735116568232
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Load MovieLens Dataset\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "movielens_zip = \"movielens.zip\"\n",
        "movielens_folder = \"ml-latest-small/\"\n",
        "\n",
        "# Download and extract the dataset\n",
        "!wget -q $url -O $movielens_zip\n",
        "!unzip -q $movielens_zip -d ./\n",
        "\n",
        "# Load the dataset\n",
        "ratings = pd.read_csv(f\"{movielens_folder}ratings.csv\")\n",
        "movies = pd.read_csv(f\"{movielens_folder}movies.csv\")\n",
        "ratings = ratings.merge(movies, on=\"movieId\")\n",
        "\n",
        "# Display dataset\n",
        "ratings.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "   userId  movieId  rating  timestamp                        title  \\\n0       1        1     4.0  964982703             Toy Story (1995)   \n1       1        3     4.0  964981247      Grumpier Old Men (1995)   \n2       1        6     4.0  964982224                  Heat (1995)   \n3       1       47     5.0  964983815  Seven (a.k.a. Se7en) (1995)   \n4       1       50     5.0  964982931   Usual Suspects, The (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                               Comedy|Romance  \n2                        Action|Crime|Thriller  \n3                             Mystery|Thriller  \n4                       Crime|Mystery|Thriller  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n      <td>Heat (1995)</td>\n      <td>Action|Crime|Thriller</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n      <td>Seven (a.k.a. Se7en) (1995)</td>\n      <td>Mystery|Thriller</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n      <td>Usual Suspects, The (1995)</td>\n      <td>Crime|Mystery|Thriller</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1735116999414
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Traditional Methods - Collaborative Filtering\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #### Prepare Dataset\n",
        "user_item_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "train_data, test_data = train_test_split(ratings, test_size=0.2)\n",
        "\n",
        "# #### Implement SVD for Collaborative Filtering\n",
        "svd = TruncatedSVD(n_components=50)\n",
        "user_factors = svd.fit_transform(user_item_matrix)\n",
        "item_factors = svd.components_.T\n",
        "\n",
        "# #### Evaluate Collaborative Filtering\n",
        "predictions = []\n",
        "for _, row in test_data.iterrows():\n",
        "    user_idx = int(row['userId'] - 1)\n",
        "    item_idx = int(row['movieId'] - 1)\n",
        "    if user_idx < user_factors.shape[0] and item_idx < item_factors.shape[0]:\n",
        "        pred = np.dot(user_factors[user_idx], item_factors[item_idx])\n",
        "        predictions.append((row['rating'], pred))\n",
        "\n",
        "true_ratings, predicted_ratings = zip(*predictions)\n",
        "rmse = mean_squared_error(true_ratings, predicted_ratings, squared=False)\n",
        "print(f\"RMSE: {rmse}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Discuss Limitations\n",
        "\n",
        "- Cold Start: No information about new users or movies.\n",
        "- Sparsity: Large datasets with few interactions.\n",
        "- Lack of Context: Can't handle textual or metadata features.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transitioning to LLM-Based Recommendations"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Semantic Matching with LLMs\n",
        "\n",
        "# #### Load Pre-Trained Transformer Model (e.g., DistilBERT)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# #### Generate Semantic Embeddings\n",
        "def get_embedding(text):\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "movies['embedding'] = movies['title'].apply(get_embedding)\n",
        "\n",
        "# #### User Query Matching\n",
        "user_query = \"I love sci-fi movies like Star Wars.\"\n",
        "user_embedding = get_embedding(user_query)\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "movies['similarity'] = movies['embedding'].apply(lambda emb: cosine_similarity(user_embedding, emb.reshape(1, -1))[0][0])\n",
        "\n",
        "# Recommend Top-5 Movies\n",
        "movies.sort_values(by='similarity', ascending=False).head(5)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a Simple LLM-Powered Recommendation System"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Movie Descriptions (Example Metadata)\n",
        "movies['description'] = \"A great movie about \" + movies['genres']\n",
        "\n",
        "# Tokenize and Generate Embeddings\n",
        "def generate_embeddings(texts):\n",
        "    tokens = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokens).last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "movies['description_embedding'] = generate_embeddings(movies['description'].tolist())\n",
        "\n",
        "# Implement Retrieval\n",
        "user_description = \"A fan of adventure and fantasy movies.\"\n",
        "user_description_embedding = generate_embeddings([user_description])\n",
        "movies['retrieval_score'] = movies['description_embedding'].apply(\n",
        "    lambda emb: cosine_similarity(user_description_embedding, emb.reshape(1, -1))[0][0]\n",
        ")\n",
        "\n",
        "# Recommend Movies\n",
        "movies.sort_values(by='retrieval_score', ascending=False).head(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Model Performance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Define Metrics for Comparison\n",
        "# - Precision@K\n",
        "# - Recall@K\n",
        "# - F1 Score\n",
        "\n",
        "# ### Compute Metrics\n",
        "def precision_at_k(true_ratings, predicted_ratings, k=5):\n",
        "    top_k = np.argsort(predicted_ratings)[-k:]\n",
        "    relevant = np.isin(top_k, true_ratings)\n",
        "    return np.sum(relevant) / k\n",
        "\n",
        "def recall_at_k(true_ratings, predicted_ratings, k=5):\n",
        "    top_k = np.argsort(predicted_ratings)[-k:]\n",
        "    relevant = np.isin(top_k, true_ratings)\n",
        "    return np.sum(relevant) / len(true_ratings)\n",
        "\n",
        "def evaluate_models(true_ratings, predicted_ratings_cf, predicted_ratings_llm):\n",
        "    k = 5\n",
        "    precision_cf = precision_at_k(true_ratings, predicted_ratings_cf, k)\n",
        "    recall_cf = recall_at_k(true_ratings, predicted_ratings_cf, k)\n",
        "    \n",
        "    precision_llm = precision_at_k(true_ratings, predicted_ratings_llm, k)\n",
        "    recall_llm = recall_at_k(true_ratings, predicted_ratings_llm, k)\n",
        "\n",
        "    print(\"Collaborative Filtering:\")\n",
        "    print(f\"Precision@{k}: {precision_cf:.2f}, Recall@{k}: {recall_cf:.2f}\")\n",
        "    print(\"LLM-Based Recommendation:\")\n",
        "    print(f\"Precision@{k}: {precision_llm:.2f}, Recall@{k}: {recall_llm:.2f}\")\n",
        "\n",
        "# Simulate Predictions for Evaluation\n",
        "predicted_ratings_llm = [pred[1] for pred in predictions]  # Using the same for simplicity\n",
        "true_ratings = [pred[0] for pred in predictions]\n",
        "evaluate_models(true_ratings, predicted_ratings, predicted_ratings_llm)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
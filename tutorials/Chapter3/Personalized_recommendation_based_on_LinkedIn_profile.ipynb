{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Extracting User Interests and Topics\n",
        "\n",
        "** Objective **\n",
        "\n",
        "Analyze LinkedIn profile text to extract structured lists of interests and topics. Use OpenAI’s GPT-4 model for semantic understanding and embeddings."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chains import load_summarize_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "\n",
        "def extract_user_interests_and_topics(linkedin_profile_text):\n",
        "    \"\"\"\n",
        "    Extracts user interests and topics from LinkedIn profile text using LangChain with GPT-4.\n",
        "\n",
        "    Args:\n",
        "        linkedin_profile_text (str): The text of the user's LinkedIn profile.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing user interests and topics with their embeddings.\n",
        "    \"\"\"\n",
        "    # Initialize LangChain components\n",
        "    loader = TextLoader(text=linkedin_profile_text)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Load summarization chain\n",
        "    llm = OpenAI(model=\"gpt-4\", temperature=0.5, max_tokens=1500)\n",
        "    chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
        "\n",
        "    # Generate summarized insights\n",
        "    summary = chain.run(documents)\n",
        "\n",
        "    # Parse insights into structured format\n",
        "    interests_prompt = (\n",
        "        f\"\"\"Given the following text, extract five key personal interests as keywords\n",
        "        and five potential topics for further learning.\n",
        "        Text: {summary}\n",
        "        Format:\n",
        "        - Interests: 1, 2, 3, 4, 5\n",
        "        - Topics: 1, 2, 3, 4, 5\n",
        "        \"\"\"\n",
        "    )\n",
        "    insights = llm(interests_prompt)\n",
        "\n",
        "    # Extract and embed interests and topics\n",
        "    interests, topics = parse_interests_and_topics(insights)\n",
        "    return {\"interests\": interests, \"topics\": topics}\n",
        "\n",
        "\n",
        "def parse_interests_and_topics(insights):\n",
        "    \"\"\"Parses interests and topics from LLM response.\"\"\"\n",
        "    lines = insights.split(\"\\n\")\n",
        "    interests = [line.split(\".\")[1].strip() for line in lines if line.startswith(\"- Interests\")]\n",
        "    topics = [line.split(\".\")[1].strip() for line in lines if line.startswith(\"- Topics\")]\n",
        "    return interests, topics\n",
        "\n",
        "# Example usage\n",
        "linkedin_text = \"Experienced data scientist skilled in machine learning, data analysis, and cloud computing.\"\n",
        "user_data = extract_user_interests_and_topics(linkedin_text)\n",
        "print(user_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding and Storing RSS Feed Content\n",
        "\n",
        "** Objective **\n",
        "\n",
        "Embed RSS feed content using OpenAI’s embedding models and store them in Weaviate for efficient retrieval."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "def embed_and_store_rss_content(rss_content_list, weaviate_client, collection_name):\n",
        "    \"\"\"\n",
        "    Embed RSS content and store embeddings in Weaviate vector database.\n",
        "\n",
        "    Args:\n",
        "        rss_content_list (list): List of RSS content strings.\n",
        "        weaviate_client (weaviate.Client): Weaviate client instance.\n",
        "        collection_name (str): Name of the Weaviate collection to store embeddings.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Initialize OpenAI embedding model\n",
        "    llm = OpenAI(model=\"text-embedding-ada-002\")\n",
        "\n",
        "    # Iterate through RSS content\n",
        "    for content in rss_content_list:\n",
        "        embedding = llm.create_embedding(input=content)\n",
        "        metadata = {\"content\": content}\n",
        "\n",
        "        # Add to Weaviate\n",
        "        weaviate_client.batch.add_data_object(\n",
        "            data_object=metadata,\n",
        "            class_name=collection_name,\n",
        "            vector=embedding\n",
        "        )\n",
        "    weaviate_client.batch.create()\n",
        "\n",
        "# Example usage\n",
        "rss_content = [\"Breaking news about AI breakthroughs\", \"New advancements in quantum computing\"]\n",
        "client = weaviate.Client(\"http://localhost:8080\")\n",
        "embed_and_store_rss_content(rss_content, client, \"RSSContent\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1725360276620
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieving Personalized Content\n",
        "\n",
        "** Objective **\n",
        "\n",
        "Retrieve RSS feed content relevant to a user’s interests using hybrid queries in Weaviate."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def retrieve_personalized_rss_feeds(weaviate_client, user_interests, collection_name, alpha=0.5, limit=5):\n",
        "    \"\"\"\n",
        "    Retrieve personalized RSS feeds based on user interests.\n",
        "\n",
        "    Args:\n",
        "        weaviate_client (weaviate.Client): Weaviate client instance.\n",
        "        user_interests (list): List of user interests as keywords.\n",
        "        collection_name (str): Weaviate collection name.\n",
        "        alpha (float): Hybrid query parameter for relevance weighting.\n",
        "        limit (int): Number of results per interest.\n",
        "\n",
        "    Returns:\n",
        "        dict: Retrieved RSS content categorized by interest.\n",
        "    \"\"\"\n",
        "    personalized_feeds = {}\n",
        "\n",
        "    for interest in user_interests:\n",
        "        response = weaviate_client.query \\\n",
        "            .get(collection_name) \\\n",
        "            .with_hybrid(query=interest, alpha=alpha) \\\n",
        "            .with_limit(limit) \\\n",
        "            .do()\n",
        "\n",
        "        results = [\n",
        "            {\n",
        "                \"title\": item[\"title\"],\n",
        "                \"content\": item[\"content\"],\n",
        "                \"score\": item[\"_additional\"][\"score\"]\n",
        "            }\n",
        "            for item in response[\"data\"][\"Get\"][collection_name]\n",
        "        ]\n",
        "\n",
        "        personalized_feeds[interest] = results\n",
        "\n",
        "    return personalized_feeds\n",
        "\n",
        "# Example usage\n",
        "user_interests = [\"AI\", \"Machine Learning\"]\n",
        "feeds = retrieve_personalized_rss_feeds(client, user_interests, \"RSSContent\")\n",
        "print(feeds)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Recommendations with LLM-Based Relevance Scoring\n",
        "** Objective **\n",
        "To assess the quality of recommendations by computing relevance scores using semantic similarity, measured by cosine similarity between user interests and RSS content embeddings."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def calculate_relevance_scores(user_embedding, rss_embeddings):\n",
        "    \"\"\"\n",
        "    Compute relevance scores for retrieved RSS content based on cosine similarity.\n",
        "\n",
        "    Args:\n",
        "        user_embedding (np.ndarray): Embedding vector of the user's interest or topic.\n",
        "        rss_embeddings (List[np.ndarray]): List of embedding vectors for RSS content.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: Relevance scores for each RSS content.\n",
        "    \"\"\"\n",
        "    scores = [cosine_similarity(user_embedding.reshape(1, -1), rss_emb.reshape(1, -1))[0][0] for rss_emb in rss_embeddings]\n",
        "    return scores\n",
        "\n",
        "def evaluate_recommendations(user_embedding, retrieved_content):\n",
        "    \"\"\"\n",
        "    Evaluate the quality of recommendations.\n",
        "\n",
        "    Args:\n",
        "        user_embedding (np.ndarray): Embedding vector of the user's interest or topic.\n",
        "        retrieved_content (List[dict]): Retrieved RSS content with embeddings and metadata.\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation metrics including mean relevance score, precision@K, and recall@K.\n",
        "    \"\"\"\n",
        "    # Extract RSS embeddings\n",
        "    rss_embeddings = [item['embedding'] for item in retrieved_content]\n",
        "    relevance_scores = calculate_relevance_scores(user_embedding, rss_embeddings)\n",
        "\n",
        "    # Define a relevance threshold\n",
        "    relevance_threshold = 0.8\n",
        "\n",
        "    # Mean Relevance Score\n",
        "    mean_score = np.mean(relevance_scores)\n",
        "\n",
        "    # Precision@K\n",
        "    K = 5\n",
        "    relevant_items = [score >= relevance_threshold for score in relevance_scores]\n",
        "    precision_at_k = sum(relevant_items[:K]) / K\n",
        "\n",
        "    # Recall@K\n",
        "    total_relevant_items = sum(relevant_items)\n",
        "    recall_at_k = sum(relevant_items[:K]) / total_relevant_items if total_relevant_items > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"Mean Relevance Score\": mean_score,\n",
        "        \"Precision@K\": precision_at_k,\n",
        "        \"Recall@K\": recall_at_k\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Extract User Interests and Topics\n",
        "linkedin_profile_text = \"Experienced in AI, ML, and data science. Passionate about cloud computing.\"\n",
        "user_data = extract_user_interests_and_topics(linkedin_profile_text)\n",
        "\n",
        "# Step 2: Embed and Store RSS Feed Content\n",
        "rss_content = [\"AI breakthroughs\", \"Quantum computing advancements\"]\n",
        "embed_and_store_rss_content(rss_content, client, \"RSSContent\")\n",
        "\n",
        "# Step 3: Retrieve Personalized Feeds\n",
        "personalized_feeds = retrieve_personalized_rss_feeds(client, user_data[\"interests\"], \"RSSContent\")\n",
        "print(personalized_feeds)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
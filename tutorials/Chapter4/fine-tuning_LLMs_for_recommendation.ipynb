{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning an LLM for Movie Recommendations\n",
        "\n",
        "#### Goals\n",
        "- Improve the model's relevance in generating recommendations.\n",
        "- Address challenges of domain-specific language and sparse user data.\n",
        "- Create a deployable recommendation pipeline.\n",
        "\n",
        "#### Requirements\n",
        "\n",
        "- A pre-trained LLM (e.g., GPT-3, GPT-4, or an open-source model like GPT-J).\n",
        "- A fine-tuning framework such as Hugging Face Transformers.\n",
        "- A movie dataset (e.g., MovieLens or IMDb).\n",
        "- Compute resources (GPU recommended)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset preparation\n",
        "\n",
        "**1. Define the Dataset**\n",
        "\n",
        "Use a dataset containing:\n",
        "\n",
        "- Movie descriptions (e.g., summaries, genres, metadata).\n",
        "- User-item interaction data (e.g., ratings, reviews, watch history).\n",
        "\n",
        "Input-Output Pair Formatting:\n",
        "\n",
        "- Input: A prompt with user context, such as:\n",
        "\n",
        "`User preferences: [list of liked movies]. Recommend 3 movies based on their taste.`\n",
        "\n",
        "- Output: A list of relevant recommendations or a response explaining the recommendations."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Preprocess the Data **\n",
        "\n",
        "- Clean and deduplicate entries.\n",
        "- Tokenize using a tokenizer matching the pre-trained LLM."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt-4\")\n",
        "data[\"input\"] = data[\"user_preferences\"] + data[\"movie_metadata\"]\n",
        "data[\"input\"] = data[\"input\"].apply(lambda x: tokenizer.encode(x, truncation=True, padding=\"max_length\"))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-Tuning Workflow\n",
        "\n",
        "** 1. Set Up the Environment **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets accelerate\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 2. Load Pre-Trained LLM and Dataset**\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "import datasets\n",
        "\n",
        "# Load pre-trained LLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt-4\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt-4\")\n",
        "\n",
        "# Load dataset\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"movie_lens\", split=\"train\")\n",
        "\n",
        "# Prepare input-output pairs\n",
        "def format_prompt(example):\n",
        "    return {\n",
        "        \"input\": f\"User preferences: {example['liked_movies']}. Recommend top movies.\",\n",
        "        \"output\": example[\"recommended_movies\"]\n",
        "    }\n",
        "\n",
        "formatted_dataset = dataset.map(format_prompt)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Define Training Configuration and fine-tune the model**\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tuned_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=formatted_dataset[\"train\"],\n",
        "    eval_dataset=formatted_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "trainer.train()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 4. Evaluate the model **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate recommendations\n",
        "prompts = [\n",
        "    \"User preferences: ['Inception', 'Interstellar', 'The Matrix']. Recommend movies.\"\n",
        "]\n",
        "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "# Decode and print results\n",
        "for i, prompt in enumerate(prompts):\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Recommendation: {tokenizer.decode(outputs[i], skip_special_tokens=True)}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deployment and Usage\n",
        "** Export the Model **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integrate into a Pipeline**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from transformers import pipeline\n",
        "import uvicorn\n",
        "\n",
        "# Initialize the FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load the fine-tuned recommendation pipeline\n",
        "recommendation_pipeline = pipeline(\"text-generation\", model=\"./fine_tuned_model\")\n",
        "\n",
        "@app.post(\"/recommend\")\n",
        "def recommend(user_preferences: str):\n",
        "    \"\"\"\n",
        "    Endpoint to generate movie recommendations based on user preferences.\n",
        "\n",
        "    Args:\n",
        "        user_preferences (str): A string describing the user's movie preferences.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the generated recommendations.\n",
        "    \"\"\"\n",
        "    prompt = f\"User preferences: {user_preferences}. Recommend movies.\"\n",
        "    response = recommendation_pipeline(prompt, max_length=150)\n",
        "    return {\"recommendations\": response[0][\"generated_text\"]}\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Entry point for running the FastAPI server.\n",
        "    \"\"\"\n",
        "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000, reload=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Iterative Improvement\n",
        "** Evaluation Metrics **\n",
        "Evaluate using:\n",
        "\n",
        "- Precision@K, Recall@K, and NDCG.\n",
        "- Cosine similarity with pre-trained embeddings to assess semantic alignment.\n",
        "\n",
        "**Automated Evaluation**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "generated_recommendations = [\"The Dark Knight\", \"Tenet\", \"Avatar\"]\n",
        "ground_truth = [\"The Dark Knight\", \"Tenet\", \"Inception\"]\n",
        "\n",
        "# Compute cosine similarity\n",
        "gen_embeddings = model.encode(generated_recommendations)\n",
        "truth_embeddings = model.encode(ground_truth)\n",
        "cosine_score = util.cos_sim(gen_embeddings, truth_embeddings)\n",
        "print(\"Cosine Similarity:\", cosine_score)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
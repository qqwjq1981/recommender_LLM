{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Conversational Shopping Assistant with Reinforcement Learning\n",
        "\n",
        "#### Objective\n",
        "\n",
        "- Recommends products based on user queries.\n",
        "- Learns from user feedback over multiple conversation rounds.\n",
        "- Dynamically adapts recommendations to enhance personalization.\n",
        "\n",
        "#### Prerequisites\n",
        "- Programming Environment\n",
        "- Python 3.8+\n",
        "- Libraries: transformers, Flask (or FastAPI), pandas, scikit-learn, numpy, gym.\n",
        "\n",
        "#### Dataset\n",
        "\n",
        "- Use the Amazon Product Dataset or a CSV file containing product details:\n",
        "-- Columns: product_id, name, category, price, description.\n",
        "\n",
        "#### Tools\n",
        "\n",
        "- Pre-trained Language Models: For natural language understanding (NLU), e.g., Hugging Faceâ€™s DistilBERT.\n",
        "- Content-Based Filtering: For initial product recommendations.\n",
        "- RL Environment: Using gym to simulate the recommendation process.\n",
        "\n",
        "\n",
        "#### Step 1: Define User Scenarios and Product data\n",
        "\n",
        "**Scenarios:**\n",
        "\n",
        "- Product Recommendations: Input: \"Recommend a laptop under $1000.\" Output: List of laptops within the price range.\n",
        "- Product Details: Input: \"Tell me about the Dell XPS 13.\" Output: Product description, price, and availability.\n",
        "\n",
        "**Dataset:** A CSV file (products.csv) containing the following:\n",
        "\n",
        "product_name, category, price, description, availability.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Build the Conversational Layer\n",
        "\n",
        "**Intent Classification**\n",
        "\n",
        "Use a zero-shot classifier (e.g., Hugging Face's BART) to identify user intent.\n",
        "\n",
        "**Entity Extraction**\n",
        "\n",
        "Extract entities like price range and category using keyword parsing or spaCy."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Zero-shot intent classifier\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "def classify_intent(user_input):\n",
        "    intents = [\"recommend\", \"product_info\", \"greeting\"]\n",
        "    result = classifier(user_input, intents)\n",
        "    return result['labels'][0]  # Top intent\n",
        "\n",
        "# OpenAI or Hugging Face's GPT-4-like model\n",
        "llm_pipeline = pipeline(\"text-generation\", model=\"gpt-3.5-turbo\")\n",
        "\n",
        "def extract_entities_with_llm(user_input):\n",
        "    prompt = f\"\"\"\n",
        "    Extract the category and price range from the following text:\n",
        "    \"{user_input}\"\n",
        "    Format your response as:\n",
        "    Category: <category>\n",
        "    Price Range: <price range>\n",
        "    \"\"\"\n",
        "    response = llm_pipeline(prompt, max_length=50)\n",
        "    result = response[0][\"generated_text\"]\n",
        "\n",
        "    # Parse results\n",
        "    category = None\n",
        "    price_range = None\n",
        "    for line in result.split(\"\\n\"):\n",
        "        if \"Category:\" in line:\n",
        "            category = line.split(\":\")[-1].strip()\n",
        "        elif \"Price Range:\" in line:\n",
        "            price_str = line.split(\":\")[-1].strip()\n",
        "            if price_str.isdigit():\n",
        "                price_range = int(price_str)\n",
        "    \n",
        "    return {\"category\": category, \"price_range\": price_range}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Implement the Recommendation Engine using LLM"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load product data\n",
        "products = pd.read_csv(\"products.csv\")\n",
        "\n",
        "# LLM for natural language recommendations\n",
        "llm = pipeline(\"text-generation\", model=\"gpt-3.5-turbo\")\n",
        "\n",
        "def recommend_products(entities):\n",
        "    category = entities.get(\"category\")\n",
        "    price_range = entities.get(\"price_range\")\n",
        "\n",
        "    # Filter products\n",
        "    filtered_products = products[\n",
        "        (products[\"category\"] == category) & (products[\"price\"] <= price_range)\n",
        "    ]\n",
        "    \n",
        "    if filtered_products.empty:\n",
        "        return \"No products found in the specified range.\"\n",
        "\n",
        "    # Format recommendations\n",
        "    recommendations = \"\\n\".join(filtered_products[\"product_name\"].tolist()[:5])\n",
        "    return f\"Here are some {category}s under ${price_range}:\\n{recommendations}\"\n",
        "\n",
        "def get_product_details(product_name):\n",
        "    product = products[products[\"product_name\"].str.contains(product_name, case=False)]\n",
        "    if product.empty:\n",
        "        return \"Product not found.\"\n",
        "    \n",
        "    details = product.iloc[0]\n",
        "    return (f\"Product: {details['product_name']}\\n\"\n",
        "            f\"Price: ${details['price']}\\n\"\n",
        "            f\"Description: {details['description']}\\n\"\n",
        "            f\"Availability: {details['availability']}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Integrate Reinforcement Learning for Multi-Turn Optimization\n",
        "\n",
        "** RL Environment Setup**\n",
        "\n",
        "Define the RL environment using gym. This environment simulates the recommendation process, where:\n",
        "\n",
        "- State Space: User preferences, conversation history, previous recommendations.\n",
        "- Action Space: Products available for recommendation.\n",
        "- Reward Signal: User feedback (e.g., clicks, purchases)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "class RecommendationEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.state = []\n",
        "        self.action_space = spaces.Discrete(len(products))\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(len(products),), dtype=float)\n",
        "    \n",
        "    def reset(self):\n",
        "        self.state = []\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        # Simulate user feedback\n",
        "        reward = 1 if action in self.state else 0\n",
        "        done = len(self.state) >= 5\n",
        "        return self.state, reward, done, {}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Build Gradio Demo\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_with_ner(user_input, conversation_history):\n",
        "    intent = classify_intent(user_input)\n",
        "    \n",
        "    # Choose between NER or LLM-based extraction\n",
        "    entities = extract_entities_with_llm(user_input)  # For GPT-4\n",
        "    # entities = extract_entities_with_ner(user_input)  # For NER Pipeline\n",
        "    \n",
        "    if intent == \"recommend\":\n",
        "        response = recommend_products(entities)\n",
        "    elif intent == \"product_info\":\n",
        "        product_name = user_input.split(\"about\")[-1].strip()\n",
        "        response = get_product_details(product_name)\n",
        "    else:\n",
        "        response = \"Hello! How can I assist you today?\"\n",
        "\n",
        "    # Maintain conversation history\n",
        "    conversation_history.append((user_input, response))\n",
        "    return conversation_history, conversation_history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Conversational Shopping Assistant\")\n",
        "    \n",
        "    chatbot = gr.Chatbot()\n",
        "    user_input = gr.Textbox(placeholder=\"Type your query here...\")\n",
        "    state = gr.State([])\n",
        "\n",
        "    user_input.submit(chat_with_ner, [user_input, state], [chatbot, state])\n",
        "\n",
        "demo.launch()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}